# docker-compose.yml

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports: ["11434:11434"]
    environment:
      OLLAMA_KEEP_ALIVE: "24h"
    volumes:
      - /home/ia-nsdas/.ollama:/root/.ollama
    gpus: all # install NVIDIA Container Toolkit
    
  backend:
      build:
        context: ./backend
        dockerfile: Dockerfile
      container_name: agent-backend
      restart: unless-stopped
      working_dir: /app
      environment:
        OLLAMA_HOST: http://ollama:11434
        PORT: "2024"
        PYTHONPATH: /app/src
      command: >
        /opt/venv/bin/langgraph dev
        --config ./langgraph.json
        --host 0.0.0.0
        --port ${PORT:-2024}
        --allow-blocking
        --no-browser
      ports:
        - "2024:2024"
      volumes:
        - ./backend:/app # Bind mount: live sync local changes to container (enables hot reload)

  frontend:
    build:
      context: ./frontend
      target: base
    container_name: agent-frontend
    restart: unless-stopped
    working_dir: /app
    environment:
      NODE_ENV: development
      NEXT_TELEMETRY_DISABLED: "1"
    command: sh -c "pnpm install && pnpm dev -p 3003 -H 0.0.0.0" # Dev: mirrors `cd frontend && pnpm dev` pending for Prod: standalone Next.js server
    ports:
      - "3003:3003"
    volumes:
      - ./frontend:/app # Bind mount: Source code hot-reload
      - frontend_node_modules:/app/node_modules # Prevents your local node_modules (if it exists) from overriding the container's node_modules
      - frontend_next_cache:/app/.next # Preserves Next.js build cache between container restarts. Speeds up subsequent builds and hot reloads

volumes:
  frontend_node_modules: # frontend volume # TODO: revisar si hace falta
  frontend_next_cache: # frontend volume # TODO: revisar si hace falta


